
### Frågor
    1. Vad tror Du vi har för skäl till att spara det skrapade datat i JSON-format?
    
    2. Olika jämförelsesiter är flitiga användare av webbskrapor. Kan du komma på fler 
        typer av tillämplingar där webbskrapor förekommer?
        
    3. Hur har du i din skrapning underlättat för serverägaren?
    
    4. Vilka etiska aspekter bör man fundera kring vid webbskrapning?
    
    5. Vad finns det för risker med applikationer som innefattar automatisk skrapning av webbsidor?
        Nämn minst ett par stycken!
        
    6. Tänk dig att du skulle skrapa en sida gjord i ASP.NET WebForms.
        Vad för extra problem skulle man kunna få då?
        
    7. Välj ut två punkter kring din kod du tycker är värd att diskutera vid redovisningen.
        Det kan röra val du gjort, tekniska lösningar eller lösningar du inte är riktigt nöjd med.
        
    8. Hitta ett rättsfall som handlar om webbskrapning. Redogör kort för detta.
    
    9. Känner du att du lärt dig något av denna uppgift?
    
    
### Svar

    1. 
    
    2. 
    
    3.
    
    4. Man bör väl kolla så att det inte är någon privat eller känslig information man skrapar.
       Man borde inte skrapa sidor utan att ha deras tillstånd. Ta hänsyn till robot.txt.
       
    5. Det finns alltid en risk att sidan ändrar sin html struktur.
    
    6. Varje gång man anropar så kräver ASP.NET-applikationen att man skickar med extra information för
        att behålla "state".
    
    7. Callback scopet.
    
    8.
    
    9. Absolut!
